{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Ratings.csv')\n",
    "df = df[df['Book-Rating'] > 0]  # remove zero ratings\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809eb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b98a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Book-Rating'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=\"Book-Rating\", data=df, order=sorted(df[\"Book-Rating\"].unique()))\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d74636",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_counts = df['ISBN'].value_counts()\n",
    "\n",
    "print(\"Unnique books:\", df['ISBN'].nunique())\n",
    "print(\"Total number of reviews:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviews per user\n",
    "user_counts = df['User-ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In item–item recommendations, each book should have at least a few reviews so that similarities can be calculated reliably.\n",
    "\n",
    "#Below we investigate how many books and how many reviews are retained at different limits (1, 2, 4, 6, 8, 10 reviews per book).\n",
    "\n",
    "thresholds = [1, 2, 4, 6, 8, 10]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for t in thresholds:\n",
    "\n",
    "    # Books with t>= reviews\n",
    "    books_to_keep = book_counts[book_counts >= t].index\n",
    "\n",
    "    # How many books remain\n",
    "    num_books_remaining = len(books_to_keep)\n",
    "\n",
    "    # Percentage of books remaining\n",
    "    pct_books_remaining = 100 * num_books_remaining / df['ISBN'].nunique()\n",
    "\n",
    "    # Filter the original dataframe to keep only reviews for those books\n",
    "    df_tmp = df[df['ISBN'].isin(books_to_keep)]\n",
    "\n",
    "    # How many reviews remain\n",
    "    num_ratings_remaining = len(df_tmp)\n",
    "\n",
    "    # Percentage of reviews remaining\n",
    "    pct_ratings_remaining = 100 * num_ratings_remaining / len(df)\n",
    "\n",
    "    # Save results\n",
    "    results[t] = {\n",
    "        \"num_books_remaining\": num_books_remaining,\n",
    "        \"pct_books_remaining\": pct_books_remaining,\n",
    "        \"num_ratings_remaining\": num_ratings_remaining,\n",
    "        \"pct_ratings_remaining\": pct_ratings_remaining\n",
    "    }\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "\n",
    "results_df[\"pct_books_remaining\"] = results_df[\"pct_books_remaining\"].round(2)\n",
    "results_df[\"pct_ratings_remaining\"] = results_df[\"pct_ratings_remaining\"].round(2)\n",
    "\n",
    "print(\"=== Results of Threshold Filtering ===\")\n",
    "display(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f61e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(results_df.index, results_df[\"pct_books_remaining\"],\n",
    "         marker=\"o\", label=\"% books remaining\")\n",
    "\n",
    "plt.plot(results_df.index, results_df[\"pct_ratings_remaining\"],\n",
    "         marker=\"o\", label=\"% ratings remaining\")\n",
    "\n",
    "plt.title(\"Threshold analysis: impact on data volume\")\n",
    "plt.xlabel(\"Threshold (min rating per book)\")\n",
    "plt.ylabel(\"Percent remaining (%)\")\n",
    "\n",
    "plt.xticks(results_df.index)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_to_keep = book_counts[book_counts >= 3].index\n",
    "\n",
    "df_filtered = df[df['ISBN'].isin(books_to_keep)].copy()\n",
    "\n",
    "df_filtered[\"ISBN\"] = (\n",
    "    df_filtered[\"ISBN\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    ")\n",
    "\n",
    "print(\"Shape after filtering:\", df_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a50802",
   "metadata": {},
   "source": [
    "Rename the columns to the format that Surprise expects (user, item, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9b3eac5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>276736</td>\n",
       "      <td>3257224281</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>276744</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>276747</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>276747</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating\n",
       "6   276736  3257224281       8\n",
       "8   276744  038550120X       7\n",
       "16  276747  0060517794       9\n",
       "19  276747  0671537458       9\n",
       "20  276747  0679776818       8"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_filtered.rename(columns={\n",
    "    'User-ID': 'user',\n",
    "    'ISBN': 'item',\n",
    "    'Book-Rating': 'rating'\n",
    "})\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171676bc",
   "metadata": {},
   "source": [
    "Verify/check the rating scale (minimum and maximum) so that Surprise can interpret the ratings correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = df_filtered['rating'].min()\n",
    "max_rating = df_filtered['rating'].max()\n",
    "\n",
    "print(f\"Rating scale: \", min_rating, \"to\", max_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8186f5",
   "metadata": {},
   "source": [
    "The filtered data is loaded into the Surprise library's Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "data = Dataset.load_from_df(\n",
    "    df_filtered[['user', 'item', 'rating']],\n",
    "    reader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aed16",
   "metadata": {},
   "source": [
    "80/20 train/test split, so the model can be evaluated on data it didn't see during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c380b5",
   "metadata": {},
   "source": [
    "# 3. Item–item KNN-mallin koulutus\n",
    "\n",
    "We train an item–item based KNNBasic model using cosine similarity. This corresponds to the typical \"since you liked this, you will probably like these too\" logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # False -> item-item similariteetti\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8742df",
   "metadata": {},
   "source": [
    "# 4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de160f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated with a test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "# MAE\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame([\n",
    "    {\n",
    "        \"user\": pred.uid,\n",
    "        \"item\": pred.iid,\n",
    "        \"true_rating\": pred.r_ui,\n",
    "        \"predicted_rating\": pred.est,\n",
    "        \"error\": pred.est - pred.r_ui\n",
    "    }\n",
    "    for pred in predictions\n",
    "])\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(pred_df[\"error\"], bins=50, kde=True)\n",
    "plt.title(\"Error distribution (predicted - true)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087248d1",
   "metadata": {},
   "source": [
    "The error distribution is roughly symmetric around zero, which suggests that the model does not have strong systematic under- or overestimation.\n",
    "\n",
    "Most of the errors are close to zero, but the distribution has wide tails: some predictions are off by several points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x=\"true_rating\", y=\"error\", data=pred_df)\n",
    "plt.title(\"Errors across different rating values\")\n",
    "plt.xlabel(\"True rating\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61c618",
   "metadata": {},
   "source": [
    "The boxplot shows how the errors are distributed with the actual rating values.\n",
    "\n",
    "The model seems to overestimate the lowest ratings badly, but the estimates between 7 and 9 are relatively accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00534ada",
   "metadata": {},
   "source": [
    "# 5. Book data (Books.csv) and recommendation functions\n",
    "\n",
    "We load Books.csv to get book titles and other metadata (e.g. author, year of publication). We then combine the predictions with the book data and build recommendation functions:\n",
    "\n",
    "user-specific recommendations\n",
    "similar books searched by book.\n",
    "We import Books.csv to display the recommended book titles and other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba40aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"Books_1.csv\", dtype=str)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc6a9a",
   "metadata": {},
   "source": [
    "We will combine the predictions with Books.csv to include the book title and other information in the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c89ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['ISBN'] = (\n",
    "    books['ISBN']\n",
    "         .astype(str)\n",
    "         .str.strip()\n",
    "         .str.upper()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d13b6e",
   "metadata": {},
   "source": [
    "Recommend books to the user based on predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5821410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_for_user(algo, df_filtered, books, user_id, n=10):\n",
    "    # All ISBNs in the dataset\n",
    "    all_items = df_filtered['item'].unique()\n",
    "\n",
    "    # Books that the user has already rated\n",
    "    rated_items = set(df_filtered[df_filtered['user'] == user_id]['item'])\n",
    "\n",
    "    # Books that the user has not rated\n",
    "    items_to_predict = [iid for iid in all_items if iid not in rated_items]\n",
    "\n",
    "    # Prediction for each remaining book\n",
    "    predictions = [algo.predict(user_id, iid) for iid in items_to_predict]\n",
    "\n",
    "    # Sort by the highest estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Take only the top n\n",
    "    top_n = predictions[:n]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    recs = pd.DataFrame([{\n",
    "        \"ISBN\": pred.iid,\n",
    "        \"predicted_rating\": pred.est\n",
    "    } for pred in top_n])\n",
    "\n",
    "    recs = recs.merge(books, on=\"ISBN\", how=\"left\")\n",
    "\n",
    "    # Remove books that were not found in Books.csv\n",
    "    recs = recs.dropna(subset=[\"Book-Title\"])\n",
    "\n",
    "    # If there are NaN book titles, create a placeholder message\n",
    "    recs['Book-Title'] = recs['Book-Title'].fillna(\"Book not found in metadata\")\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185de3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = recommend_books_for_user(algo, df_filtered, books, user_id=\"188100\", n=4)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf4c78",
   "metadata": {},
   "source": [
    "Creating a book recommendation based on the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for books by name\n",
    "\n",
    "def find_book_by_title(books, title):\n",
    "    matches = books[books['Book-Title'].str.contains(title, case=False, na=False)]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b933b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for searching books using KNN model\n",
    "\n",
    "def recommend_by_title(algo, books, title, n=10):\n",
    "# Find books whose title contains the search keyword\n",
    "    matches = find_book_by_title(books, title)\n",
    "\n",
    "    if matches.empty:\n",
    "        return f\"No matches found for book title '{title}'.\"\n",
    "\n",
    "    # Use the first match\n",
    "    target = matches.iloc[0]\n",
    "    target_isbn = target['ISBN']\n",
    "\n",
    "    print(f\"Using ISBN {target_isbn} for book '{target['Book-Title']}'\")\n",
    "\n",
    "    # Convert ISBN into Surprise library's internal ID format\n",
    "    try:\n",
    "        inner_id = algo.trainset.to_inner_iid(target_isbn)\n",
    "    except:\n",
    "        return \"This book was not included in the training data, so similarities cannot be calculated.\"\n",
    "\n",
    "    # Retrieve k nearest neighbors (most similar books)\n",
    "    neighbors = algo.get_neighbors(inner_id, k=n)\n",
    "\n",
    "    # Convert internal IDs back into original ISBN values\n",
    "    neighbor_isbns = [algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "\n",
    "    # Return books whose ISBN is in the neighbors\n",
    "    recs = books[books['ISBN'].isin(neighbor_isbns)]\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6de0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_by_title(algo, books, \"lord of the rings\", n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb41b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_for_user(algo, df_filtered, books, user_id, n=10):\n",
    "    # Kaikki ISBN datasetissä\n",
    "    all_items = df_filtered['item'].unique()\n",
    "\n",
    "    # Kirjat jotka käyttäjä on jo arvostellut\n",
    "    rated_items = set(df_filtered[df_filtered['user'] == user_id]['item'])\n",
    "\n",
    "    # Kirjat joita käyttäjä ei ole arvostellut\n",
    "    items_to_predict = [iid for iid in all_items if iid not in rated_items]\n",
    "\n",
    "    # Ennuste jokaiselle lopulle kirjalle\n",
    "    predictions = [algo.predict(user_id, iid) for iid in items_to_predict]\n",
    "\n",
    "    # Järjestetään suurimman arvioidun ratingin mukaan\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    # Otetaan vain n parasta\n",
    "    top_n = predictions[:n]\n",
    "\n",
    "    # Muutetaan DataFrameksi\n",
    "    recs = pd.DataFrame([{\n",
    "        \"ISBN\": pred.iid,\n",
    "        \"predicted_rating\": pred.est\n",
    "    } for pred in top_n])\n",
    "\n",
    "    recs = recs.merge(books, on=\"ISBN\", how=\"left\")\n",
    "\n",
    "    # Poistetaan kirjat jotka eivät löytyneet Books.csv:stä\n",
    "    recs = recs.dropna(subset=[\"Book-Title\"])\n",
    "\n",
    "    # Jos tulee NaN kirjoja luodaan ilmoitus\n",
    "    recs['Book-Title'] = recs['Book-Title'].fillna(\"Kirjaa ei löytynyt metadatasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad483f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install nbconvert\n",
    "\n",
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "# Load notebook\n",
    "with open(\"book_reco_improved.ipynb\") as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Convert to HTML\n",
    "html_exporter = HTMLExporter()\n",
    "(body, resources) = html_exporter.from_notebook_node(nb)\n",
    "\n",
    "# Save HTML\n",
    "with open(\"book_reco_improved.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
